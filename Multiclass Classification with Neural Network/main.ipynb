{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 1\n",
    "import keras\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import util_mnist_reader\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "losstrack = []\n",
    "\n",
    "x_train, y_train = util_mnist_reader.load_mnist('../data/fashion', kind='train')\n",
    "x_test, y_test = util_mnist_reader.load_mnist('../data/fashion', kind='t10k')\n",
    "\n",
    "# for feature in x_train.columns:\n",
    "#     max_value = df[feature].max()\n",
    "#     min_value = df[feature].min()\n",
    "#     x[feature] = (df[feature] - min_value) / (max_value - min_value)  #NORMALIZATION\n",
    "   \n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.10, random_state = 16)  \n",
    "#SPLITTING INTO 80% TRAIN 10% VALIDATION\n",
    "\n",
    "#normalization\n",
    "x_train=x_train.astype('float32')\n",
    "x_train = x_train/255\n",
    "x_test=x_test.astype('float32')\n",
    "x_test = x_test/255\n",
    "x_val=x_val.astype('float32')\n",
    "x_val = x_val/255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "\n",
    "# y_train = y_train.reshape( y_train.shape[0],1)\n",
    "# y_test = y_test.reshape( y_test.shape[0],1)\n",
    "# y_val = y_val.reshape( y_val.shape[0],1)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "print('xval shape',x_val.shape)\n",
    "print('yval shape',y_val.shape)\n",
    "\n",
    "\n",
    "#INITIALISATION\n",
    "epochs = 50\n",
    "learningrate = 0.01\n",
    "hiddenlayers=1024\n",
    "\n",
    "# def loss(a,y):        \n",
    "#     loss1=np.sum(np.multiply(y_train,np.log(p2)))\n",
    "#     m=y_train.shape[0]\n",
    "#     loss= -(1/m) * loss1\n",
    "#     return loss\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "losstrack = [] #ARRAY OF LOSS\n",
    "\n",
    "def softmax(z1):\n",
    "    return np.exp(z1) / np.sum(np.exp(z1))\n",
    "\n",
    "\n",
    "w1 = np.random.randn(x_train.shape[1], hiddenlayers)\n",
    "b1 = np.zeros(hiddenlayers)\n",
    "w2 = np.random.randn(hiddenlayers, 10)\n",
    "b2 = np.zeros(10)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #forward prop\n",
    "    z1 = np.dot( x_train,w1) + b1\n",
    "    p1 = sigmoid(z1)\n",
    "    z2 = np.dot( p1,w2) + b2\n",
    "    p2 = softmax(z2)\n",
    "   \n",
    "    loss1=np.sum(np.multiply(y_train,np.log(p2)))\n",
    "    m=y_train.shape[0]\n",
    "    loss= -(1/m) * loss1\n",
    "    losstrack.append(np.squeeze(loss))\n",
    "   \n",
    "    #backward prop\n",
    "   \n",
    "    result1=p2 - y_train\n",
    "    val=np.dot(result1,w2.T)\n",
    "    result2=np.multiply(p1 , (1-p1))\n",
    "    result3=np.multiply(val,result2)\n",
    "   \n",
    "    dw2=(1./m) * np.dot(result1.T,p1)\n",
    "    db2=(1./m)*np.sum(result1)\n",
    "   \n",
    "    dw1=(1./m) * np.dot(x_train.T,result3)\n",
    "    db1=(1./m)*np.sum(result3)\n",
    "   \n",
    "\n",
    "    w1 = w1 - learningrate * dw1\n",
    "    b1 = b1 - learningrate * db1\n",
    "    w2 = w2 - learningrate * dw2.T\n",
    "    b2 = b2 - learningrate * db2\n",
    "   \n",
    "    print(\"epoch\")\n",
    "    print(epoch)\n",
    "    print(\"loss\")\n",
    "    print(loss)\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "plt.figure(1) #graph : training set vs epochs\n",
    "plt.title(\"TRAINING SET\")\n",
    "plt.xlabel(\"EPOC\")\n",
    "plt.ylabel(\"COST\")\n",
    "plt.plot(losstrack,label='TRAINING SET')\n",
    "plt.legend()\n",
    "z1 = np.dot( x_test,w1) + b1\n",
    "p1 = sigmoid(z1)\n",
    "z2 = np.dot( p1,w2) + b2\n",
    "p2 = softmax(z2)\n",
    "\n",
    "predictions = np.argmax(p2, axis=1)\n",
    "labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(confusion_matrix(predictions, labels))\n",
    "print(classification_report(predictions, labels))\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(predictions,labels ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task2\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import util_mnist_reader\n",
    "import keras\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Dropout, Activation,Flatten\n",
    "x_train, y_train = util_mnist_reader.load_mnist('../data/fashion', kind='train')\n",
    "x_test, y_test = util_mnist_reader.load_mnist('../data/fashion', kind='t10k')\n",
    "\n",
    "\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train1)\n",
    "\n",
    "y_test = keras.utils.to_categorical(y_test1)\n",
    "x_train=x_train.reshape(x_train.shape[0],28,28)\n",
    "x_test=x_test.reshape(x_test.shape[0],28,28)\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape, \"y_test shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(128, activation='relu', input_shape=(28,28)))\n",
    "\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "fit1=model.fit(x_train, y_train,validation_data=(x_test,y_test),epochs=100,batch_size=512)\n",
    "plt.plot(fit1.history['loss'])\n",
    "plt.plot(fit1.history['val_loss'])\n",
    "plt.title(\"loss vs epoch\")\n",
    "plt.plot(loss,label='TRAINING SET')\n",
    "plt.plot(val_loss,label='VALIDATION SET')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n",
    "# score = model.evaluate(x_test, y_test, batch_size=128)\n",
    "# print(score)\n",
    "\n",
    "#Model evaluation\n",
    "y_pred = model.predict(x_test)\n",
    "#Converting predictions to label\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(y_test)):\n",
    "    test.append(np.argmax(y_test[i]))\n",
    "\n",
    "a = accuracy_score(pred,test)\n",
    "print('Accuracy is:', a*100)\n",
    "\n",
    "#Confusion matrix\n",
    "cm = confusion_matrix(test,pred)\n",
    "print(\"Confusion matrix is:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 3\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "import util_mnist_reader\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "x_train, y_train = util_mnist_reader.load_mnist('../data/fashion', kind='train')\n",
    "x_test, y_test = util_mnist_reader.load_mnist('../data/fashion', kind='t10k')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "x_test = x_test.reshape(10000,28,28,1)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5,5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "fit1=model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "plt.plot(fit1.history['loss'])\n",
    "plt.plot(fit1.history['val_loss'])\n",
    "plt.plot(loss,label='TRAINING SET')\n",
    "plt.plot(val_loss,label='VALIDATION SET')\n",
    "plt.title(\"loss vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    "#Model evaluation\n",
    "y_pred = model.predict(x_test)\n",
    "#Converting predictions to label\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(y_test)):\n",
    "    test.append(np.argmax(y_test[i]))\n",
    "\n",
    "a = accuracy_score(pred,test)\n",
    "print('Accuracy is:', a*100)\n",
    "\n",
    "#Confusion matrix\n",
    "cm = confusion_matrix(test,pred)\n",
    "print(\"Confusion matrix is:\")\n",
    "print(cm)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
